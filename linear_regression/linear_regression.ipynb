{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 학습 데이터(training data) 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([2,3,4,5,6]).reshape(5,1)\n",
    "\n",
    "# raw_data = [[1,2],[2,3],[3,4],[4,5],[5,6]] 과 같이 입력과 결과값이 \n",
    "# 같이 있는 데이터라면 입력값과 결과값을 slicing, list comprehension 등을\n",
    "# 이용해서 분리해줘야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 임의의 직선 y=Wx+b 정의 (임의의 값으로 가중치 W, 바이어스 b초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W=  [[0.34520951]] , W shape =  (1, 1) , b =  [0.15000346] , b.shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W= \",W, \", W shape = \", W.shape, \", b = \",b, \", b.shape =\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 손실함수 E(W,b) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W)+b\n",
    "    return (np.sum((t-y)**2))/(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 수치미분 numerical_derivative 및 utility 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분 구현\n",
    "def numerical_derivative(f,x): # x에 변수가 여러개\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    # 주어진 어레이와 같은 형태와 타입을 갖는 0으로 채워진 어레이를 반환\n",
    "    # grad는 계산된 수치미분 값을 저장할 변수\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #  op_flags를 이용하면 기본값은 읽기 전용이지만 읽기/쓰기 또는 \n",
    "    # 쓰기 전용 모드로 설정할 수 있다\n",
    "    # multi_index는 뭐지..?\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        # x의 원본값이 변화되는 것을 막고자 임시변수 tmp_val 이라는 곳에\n",
    "        # 원본값을 저장해두고 있다\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_X)\n",
    "        \n",
    "        x[idx]=tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_X)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W)+b\n",
    "    return (np.sum((t-y)**2))/(len(x)) \n",
    "\n",
    "# 학습을 모두 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "def predict(x):\n",
    "    y=np.dot(x,W)+b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 학습율(learning rate) 초기화 및 손실함수가 최소가 될 때까지 W,b 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial erorr value =  8.778168481691937\n",
      "Initial W =  [[0.34520951]]\n",
      "Initial b =  [0.15000346]\n",
      "step =  0\n",
      "error_value =  5.195292492705254\n",
      "W =  [[0.54026321]]\n",
      "b =  [0.1945876]\n",
      "step =  400\n",
      "error_value =  0.005154307810315621\n",
      "W =  [[1.04662103]]\n",
      "b =  [0.83172447]\n",
      "step =  800\n",
      "error_value =  0.0003288753104258289\n",
      "W =  [[1.01177639]]\n",
      "b =  [0.95749388]\n",
      "step =  1200\n",
      "error_value =  2.0984189107070373e-05\n",
      "W =  [[1.0029747]]\n",
      "b =  [0.98926303]\n",
      "step =  1600\n",
      "error_value =  1.3389153229867645e-06\n",
      "W =  [[1.0007514]]\n",
      "b =  [0.99728786]\n",
      "step =  2000\n",
      "error_value =  8.543071323756072e-08\n",
      "W =  [[1.0001898]]\n",
      "b =  [0.99931492]\n",
      "step =  2400\n",
      "error_value =  5.4509845686133426e-09\n",
      "W =  [[1.00004794]]\n",
      "b =  [0.99982695]\n",
      "step =  2800\n",
      "error_value =  3.478050415582435e-10\n",
      "W =  [[1.00001211]]\n",
      "b =  [0.99995629]\n",
      "step =  3200\n",
      "error_value =  2.2192017868295632e-11\n",
      "W =  [[1.00000306]]\n",
      "b =  [0.99998896]\n",
      "step =  3600\n",
      "error_value =  1.4159819377951313e-12\n",
      "W =  [[1.00000077]]\n",
      "b =  [0.99999721]\n",
      "step =  4000\n",
      "error_value =  9.034801897239177e-14\n",
      "W =  [[1.0000002]]\n",
      "b =  [0.9999993]\n",
      "step =  4400\n",
      "error_value =  5.764737758031302e-15\n",
      "W =  [[1.00000005]]\n",
      "b =  [0.99999982]\n",
      "step =  4800\n",
      "error_value =  3.678243415187554e-16\n",
      "W =  [[1.00000001]]\n",
      "b =  [0.99999996]\n",
      "step =  5200\n",
      "error_value =  2.3469368701415754e-17\n",
      "W =  [[1.]]\n",
      "b =  [0.99999999]\n",
      "step =  5600\n",
      "error_value =  1.4974844611040633e-18\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n",
      "step =  6000\n",
      "error_value =  9.554840890793807e-20\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n",
      "step =  6400\n",
      "error_value =  6.096476231440355e-21\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n",
      "step =  6800\n",
      "error_value =  3.8899165647357455e-22\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n",
      "step =  7200\n",
      "error_value =  2.4817079254201445e-23\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n",
      "step =  7600\n",
      "error_value =  1.5847403157765362e-24\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n",
      "step =  8000\n",
      "error_value =  1.0138215528542455e-25\n",
      "W =  [[1.]]\n",
      "b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2 #발산하는 경우, 1e-3, 1e-6 등으로 바꿔서 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"Initial erorr value = \", error_val(x_data,t_data))\n",
    "print(\"Initial W = \",W)\n",
    "print(\"Initial b = \",b)\n",
    "\n",
    "for step in range(8001):\n",
    "    W = W - learning_rate * numerical_derivative(f,W)\n",
    "    b = b - learning_rate * numerical_derivative(f,b)\n",
    "    if(step % 400 == 0):\n",
    "        print(\"step = \", step )\n",
    "        print(\"error_value = \", error_val(x_data,t_data))\n",
    "        print(\"W = \",W)\n",
    "        print(\"b = \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Variable regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -학습 데이터 (training data) 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = np.loadtxt('./data-01-test-score.csv',delimiter=',',dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[:,0:-1]\n",
    "t_data = loaded_data[:,[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 임의의 직선 y=Wx+b 정의 (임의의 값으로 가중치 W, 바이어스 b초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W=  [[0.46665824]\n",
      " [0.10741838]\n",
      " [0.84510498]] , W shape =  (3, 1) , b =  [0.16857499] , b.shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3,1) #3X1 행렬\n",
    "b = np.random.rand(1)\n",
    "print(\"W= \",W, \", W shape = \", W.shape, \", b = \",b, \", b.shape =\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 아래부터는 single variable과 마찬가지로 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 손실함수 E(W,b) 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 수치미분 numerical_derivative 및 utility 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 학습율(learning rate) 초기화 및 손실함수가 최소가 될 때까지 W,b 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial erorr value =  2326.4299138009055\n",
      "Initial W =  [[0.46665824]\n",
      " [0.10741838]\n",
      " [0.84510498]]\n",
      "Initial b =  [0.16857499]\n",
      "step =  0\n",
      "error_value =  865.2651269298793\n",
      "W =  [[0.54352234]\n",
      " [0.18484989]\n",
      " [0.9242803 ]]\n",
      "b =  [0.16915318]\n",
      "step =  400\n",
      "error_value =  7.7140554671142505\n",
      "W =  [[0.63394234]\n",
      " [0.33037119]\n",
      " [1.05032306]]\n",
      "b =  [0.16945901]\n",
      "step =  800\n",
      "error_value =  7.4128961636229915\n",
      "W =  [[0.60770978]\n",
      " [0.35277737]\n",
      " [1.05392914]]\n",
      "b =  [0.16886053]\n",
      "step =  1200\n",
      "error_value =  7.170451309573304\n",
      "W =  [[0.58393884]\n",
      " [0.37249391]\n",
      " [1.05777127]]\n",
      "b =  [0.16825678]\n",
      "step =  1600\n",
      "error_value =  6.974834460053713\n",
      "W =  [[0.56240084]\n",
      " [0.38986767]\n",
      " [1.06173274]]\n",
      "b =  [0.16764766]\n",
      "step =  2000\n",
      "error_value =  6.816686425010574\n",
      "W =  [[0.54288798]\n",
      " [0.40519765]\n",
      " [1.06572332]]\n",
      "b =  [0.16703315]\n",
      "step =  2400\n",
      "error_value =  6.68860554511898\n",
      "W =  [[0.52521145]\n",
      " [0.41874204]\n",
      " [1.06967421]]\n",
      "b =  [0.16641334]\n",
      "step =  2800\n",
      "error_value =  6.584714662881695\n",
      "W =  [[0.50919979]\n",
      " [0.43072406]\n",
      " [1.0735339 ]]\n",
      "b =  [0.1657884]\n",
      "step =  3200\n",
      "error_value =  6.500330003969152\n",
      "W =  [[0.49469733]\n",
      " [0.44133699]\n",
      " [1.07726479]]\n",
      "b =  [0.1651585]\n",
      "step =  3600\n",
      "error_value =  6.431706484796486\n",
      "W =  [[0.48156277]\n",
      " [0.45074847]\n",
      " [1.08084042]]\n",
      "b =  [0.16452388]\n",
      "step =  4000\n",
      "error_value =  6.375840680641835\n",
      "W =  [[0.46966787]\n",
      " [0.45910408]\n",
      " [1.08424312]]\n",
      "b =  [0.16388478]\n",
      "step =  4400\n",
      "error_value =  6.330317560807487\n",
      "W =  [[0.45889629]\n",
      " [0.46653047]\n",
      " [1.0874622 ]]\n",
      "b =  [0.16324146]\n",
      "step =  4800\n",
      "error_value =  6.293190646126018\n",
      "W =  [[0.44914251]\n",
      " [0.47313795]\n",
      " [1.09049241]]\n",
      "b =  [0.16259417]\n",
      "step =  5200\n",
      "error_value =  6.262887841182146\n",
      "W =  [[0.44031082]\n",
      " [0.47902279]\n",
      " [1.09333271]]\n",
      "b =  [0.16194319]\n",
      "step =  5600\n",
      "error_value =  6.238137103808449\n",
      "W =  [[0.43231444]\n",
      " [0.48426908]\n",
      " [1.09598523]]\n",
      "b =  [0.16128877]\n",
      "step =  6000\n",
      "error_value =  6.217907526921966\n",
      "W =  [[0.42507468]\n",
      " [0.48895044]\n",
      " [1.09845452]]\n",
      "b =  [0.16063116]\n",
      "step =  6400\n",
      "error_value =  6.201362458140227\n",
      "W =  [[0.41852022]\n",
      " [0.49313137]\n",
      " [1.10074685]]\n",
      "b =  [0.15997059]\n",
      "step =  6800\n",
      "error_value =  6.187822068254717\n",
      "W =  [[0.41258642]\n",
      " [0.49686849]\n",
      " [1.10286972]]\n",
      "b =  [0.15930731]\n",
      "step =  7200\n",
      "error_value =  6.17673337078907\n",
      "W =  [[0.4072147 ]\n",
      " [0.50021155]\n",
      " [1.10483142]]\n",
      "b =  [0.15864151]\n",
      "step =  7600\n",
      "error_value =  6.167646142370635\n",
      "W =  [[0.40235198]\n",
      " [0.50320435]\n",
      " [1.10664076]]\n",
      "b =  [0.15797342]\n",
      "step =  8000\n",
      "error_value =  6.160193534465134\n",
      "W =  [[0.39795016]\n",
      " [0.50588551]\n",
      " [1.10830674]]\n",
      "b =  [0.15730322]\n",
      "step =  8400\n",
      "error_value =  6.154076428153346\n",
      "W =  [[0.39396566]\n",
      " [0.50828908]\n",
      " [1.10983842]]\n",
      "b =  [0.1566311]\n",
      "step =  8800\n",
      "error_value =  6.1490507848772475\n",
      "W =  [[0.39035901]\n",
      " [0.51044518]\n",
      " [1.11124473]]\n",
      "b =  [0.15595721]\n",
      "step =  9200\n",
      "error_value =  6.144917402059625\n",
      "W =  [[0.38709446]\n",
      " [0.51238045]\n",
      " [1.11253439]]\n",
      "b =  [0.15528173]\n",
      "step =  9600\n",
      "error_value =  6.141513604045446\n",
      "W =  [[0.38413962]\n",
      " [0.51411849]\n",
      " [1.11371581]]\n",
      "b =  [0.15460479]\n",
      "step =  10000\n",
      "error_value =  6.1387064940137295\n",
      "W =  [[0.38146517]\n",
      " [0.51568022]\n",
      " [1.11479702]]\n",
      "b =  [0.15392652]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5 #1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"Initial erorr value = \", error_val(x_data,t_data))\n",
    "print(\"Initial W = \",W)\n",
    "print(\"Initial b = \",b)\n",
    "\n",
    "for step in range(10001):\n",
    "    W = W - learning_rate * numerical_derivative(f,W)\n",
    "    b = b - learning_rate * numerical_derivative(f,b)\n",
    "    if(step % 400 == 0):\n",
    "        print(\"step = \", step )\n",
    "        print(\"error_value = \", error_val(x_data,t_data))\n",
    "        print(\"W = \",W)\n",
    "        print(\"b = \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.13566394])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100,98,81])\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
