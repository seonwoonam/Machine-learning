{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogicGate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 외부 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### external function (sigmoid, numerical_derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "# 수치미분 함수\n",
    "def numerical_derivative(f,x): # x에 변수가 여러개\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    # 주어진 어레이와 같은 형태와 타입을 갖는 0으로 채워진 어레이를 반환\n",
    "    # grad는 계산된 수치미분 값을 저장할 변수\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #  op_flags를 이용하면 기본값은 읽기 전용이지만 읽기/쓰기 또는 \n",
    "    # 쓰기 전용 모드로 설정할 수 있다\n",
    "    # multi_index는 뭐지..?\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        # x의 원본값이 변화되는 것을 막고자 임시변수 tmp_val 이라는 곳에\n",
    "        # 원본값을 저장해두고 있다\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_X)\n",
    "        \n",
    "        x[idx]=tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_X)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogicGate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        # 입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4,2)\n",
    "        self.__tdata = tdata.reshape(4,1)\n",
    "        \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        self.__W = np.random.rand(2,1)\n",
    "        self.__b = np.random.rand(1)\n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "    # 손실함수\n",
    "    def __loss_func(self):\n",
    "        delta = 1e-7\n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return -np.sum(self.__tdata*np.log(y+delta)+(1-self.__tdata)*np.log((1-y)+delta))\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def error_val(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z = np.dot(self.__xdata, self.__W) + self.__b\n",
    "        y = sigmoid(z)\n",
    "        \n",
    "        return -np.sum(self.__tdata*np.log(y+delta)+(1-self.__tdata)*np.log((1-y)+delta))\n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x : self.__loss_func()\n",
    "        print(\"Initial erorr value = \", self.error_val())\n",
    "\n",
    "        for step in range(8001):\n",
    "\n",
    "            self.__W -= self.__learning_rate*numerical_derivative(f,self.__W)\n",
    "            self.__b -= self.__learning_rate*numerical_derivative(f,self.__b)\n",
    "            if(step % 400 == 0):\n",
    "                print(\"step = \", step )\n",
    "                print(\"error_value = \", self.error_val())\n",
    "                    \n",
    "    # 학습을 모두 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "    def predict(self, input_data):\n",
    "\n",
    "        z=np.dot(input_data,self.__W)+self.__b\n",
    "        y=sigmoid(z)\n",
    "\n",
    "        if y>0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND GATE 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial erorr value =  4.983359130665479\n",
      "step =  0\n",
      "error_value =  4.920477327061232\n",
      "step =  400\n",
      "error_value =  1.568791971821438\n",
      "step =  800\n",
      "error_value =  1.1579619414990994\n",
      "step =  1200\n",
      "error_value =  0.9280894658013815\n",
      "step =  1600\n",
      "error_value =  0.777373069321113\n",
      "step =  2000\n",
      "error_value =  0.6694488899843059\n",
      "step =  2400\n",
      "error_value =  0.5878154027711444\n",
      "step =  2800\n",
      "error_value =  0.5237120762738244\n",
      "step =  3200\n",
      "error_value =  0.47197218255526097\n",
      "step =  3600\n",
      "error_value =  0.42931530996592715\n",
      "step =  4000\n",
      "error_value =  0.39354292980400923\n",
      "step =  4400\n",
      "error_value =  0.3631194694076938\n",
      "step =  4800\n",
      "error_value =  0.33693683652448925\n",
      "step =  5200\n",
      "error_value =  0.3141739325301419\n",
      "step =  5600\n",
      "error_value =  0.2942087528122908\n",
      "step =  6000\n",
      "error_value =  0.2765612152350049\n",
      "step =  6400\n",
      "error_value =  0.2608547575328354\n",
      "step =  6800\n",
      "error_value =  0.24678983057940157\n",
      "step =  7200\n",
      "error_value =  0.2341251709106549\n",
      "step =  7600\n",
      "error_value =  0.22266429876961358\n",
      "step =  8000\n",
      "error_value =  0.21224560894702724\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,0,0,1]) # 정답데이터\n",
    "\n",
    "AND_obj = LogicGate(\"AND_GATE\", xdata, tdata)\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] = 0 \n",
      "\n",
      "[0 1] = 0 \n",
      "\n",
      "[1 0] = 0 \n",
      "\n",
      "[1 1] = 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR GATE, NAND GATE 모두 검증가능\n",
    "### ==> XOR GATE의 경우 손실함수 값이 줄지않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial erorr value =  2.638056641233497\n",
      "step =  0\n",
      "error_value =  2.6337874013316673\n",
      "step =  400\n",
      "error_value =  1.6003815292580978\n",
      "step =  800\n",
      "error_value =  1.1743587641969406\n",
      "step =  1200\n",
      "error_value =  0.9383401171917416\n",
      "step =  1600\n",
      "error_value =  0.7844837481294966\n",
      "step =  2000\n",
      "error_value =  0.6747090938226588\n",
      "step =  2400\n",
      "error_value =  0.5918791284657003\n",
      "step =  2800\n",
      "error_value =  0.5269512645623807\n",
      "step =  3200\n",
      "error_value =  0.47461632753142174\n",
      "step =  3600\n",
      "error_value =  0.4315147827299829\n",
      "step =  4000\n",
      "error_value =  0.3954008725783206\n",
      "step =  4400\n",
      "error_value =  0.36470921857403726\n",
      "step =  4800\n",
      "error_value =  0.33831207022445353\n",
      "step =  5200\n",
      "error_value =  0.31537489254745843\n",
      "step =  5600\n",
      "error_value =  0.2952662227083737\n",
      "step =  6000\n",
      "error_value =  0.27749915377092066\n",
      "step =  6400\n",
      "error_value =  0.2616920936344728\n",
      "step =  6800\n",
      "error_value =  0.24754171771853278\n",
      "step =  7200\n",
      "error_value =  0.23480388283038325\n",
      "step =  7600\n",
      "error_value =  0.22327988128948528\n",
      "step =  8000\n",
      "error_value =  0.2128063622471227\n",
      "[0 0] = 1 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 0 \n",
      "\n",
      "---------------------------------------\n",
      "Initial erorr value =  2.0684588415009513\n",
      "step =  0\n",
      "error_value =  2.0562302327117776\n",
      "step =  400\n",
      "error_value =  1.0872425540024784\n",
      "step =  800\n",
      "error_value =  0.7906058429759952\n",
      "step =  1200\n",
      "error_value =  0.6157354228720445\n",
      "step =  1600\n",
      "error_value =  0.5013882959612193\n",
      "step =  2000\n",
      "error_value =  0.4212366955905346\n",
      "step =  2400\n",
      "error_value =  0.3622002851356911\n",
      "step =  2800\n",
      "error_value =  0.3170629051323491\n",
      "step =  3200\n",
      "error_value =  0.2815281322348008\n",
      "step =  3600\n",
      "error_value =  0.25288551053579833\n",
      "step =  4000\n",
      "error_value =  0.22934515393093463\n",
      "step =  4400\n",
      "error_value =  0.20968028725830762\n",
      "step =  4800\n",
      "error_value =  0.19302362852076635\n",
      "step =  5200\n",
      "error_value =  0.1787457281238956\n",
      "step =  5600\n",
      "error_value =  0.16637931952071391\n",
      "step =  6000\n",
      "error_value =  0.15557065704201625\n",
      "step =  6400\n",
      "error_value =  0.14604728345249596\n",
      "step =  6800\n",
      "error_value =  0.13759612707353058\n",
      "step =  7200\n",
      "error_value =  0.13004827862717558\n",
      "step =  7600\n",
      "error_value =  0.12326819632465474\n",
      "step =  8000\n",
      "error_value =  0.11714591233442463\n",
      "[0 0] = 0 \n",
      "\n",
      "[0 1] = 1 \n",
      "\n",
      "[1 0] = 1 \n",
      "\n",
      "[1 1] = 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([1,1,1,0]) # 정답데이터\n",
    "\n",
    "NAND_obj = LogicGate(\"NAND_GATE\", xdata, tdata)\n",
    "NAND_obj.train()\n",
    "\n",
    "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = NAND_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val, \"\\n\")\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,1,1,1]) # 정답데이터\n",
    "\n",
    "OR_obj = LogicGate(\"OR_GATE\", xdata, tdata)\n",
    "OR_obj.train()\n",
    "\n",
    "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = OR_obj.predict(input_data)\n",
    "    print(input_data, \"=\", logical_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해결 방법: NAND, OR, AND 조합으로 XOR 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  =  0\n",
      "\n",
      "[0 1]  =  1\n",
      "\n",
      "[1 0]  =  1\n",
      "\n",
      "[1 1]  =  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "s1 = [] #NAND 출력\n",
    "s2 = [] #OR 출력\n",
    "\n",
    "new_input_data = [] #AND 입력\n",
    "final_output = []   #AND 출력\n",
    "\n",
    "for index in range(len(input_data)):\n",
    "    s1 = NAND_obj.predict(input_data[index])\n",
    "    s2 = OR_obj.predict(input_data[index])\n",
    "    \n",
    "    new_input_data.append(s1[-1])\n",
    "    new_input_data.append(s2[-1])\n",
    "    \n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(np.array(new_input_data))\n",
    "    \n",
    "    final_output.append(logical_val)\n",
    "    new_input_data = []\n",
    "    \n",
    "for index in range(len(input_data)):\n",
    "    print(input_data[index],\" = \", final_output[index], end='')\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### => 머신러닝 XOR 문제는 다양한 GATE의 조합인 Multi-Layer로 해결할 수 있음\n",
    "#### 이전 Gate의 출력이 다음 Gate의 입력으로 들어간다는 아이디어는 신경망 기반의 딥러닝의 핵심 아이디어이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
