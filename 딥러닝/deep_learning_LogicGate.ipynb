{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝을 이용해서 XOR 문제 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### external function (sigmoid, numerical_derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시그모이드 함수\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "# 수치미분 함수\n",
    "def numerical_derivative(f,x): # x에 변수가 여러개\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    # 주어진 어레이와 같은 형태와 타입을 갖는 0으로 채워진 어레이를 반환\n",
    "    # grad는 계산된 수치미분 값을 저장할 변수\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags=['readwrite'])\n",
    "    #  op_flags를 이용하면 기본값은 읽기 전용이지만 읽기/쓰기 또는 \n",
    "    # 쓰기 전용 모드로 설정할 수 있다\n",
    "    # multi_index는 뭐지..?\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        # x의 원본값이 변화되는 것을 막고자 임시변수 tmp_val 이라는 곳에\n",
    "        # 원본값을 저장해두고 있다\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_X)\n",
    "        \n",
    "        x[idx]=tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x-delta_X)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogicGate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        self.name = gate_name\n",
    "        \n",
    "        # 입력 데이터, 정답 데이터 초기화\n",
    "        # 입력 데이터와 정답 데이터를 처리하는 작엄을 batch 작업이라한다\n",
    "        self.__xdata = xdata.reshape(4,2)\n",
    "        self.__tdata = tdata.reshape(4,1)\n",
    "        \n",
    "        # 2층(입력층과 은닉층 사이)가중치 W, 바이어스 b 초기화\n",
    "        # 한번에 입력되는 데이터 2개\n",
    "        # 은닉층 노드는 6개로 가정\n",
    "        self.__W2 = np.random.rand(2,6)\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        \n",
    "        # 3층(은닉층과 출력층 사이)\n",
    "        # 은닉층의 노드수 : 6개\n",
    "        # 출력층의 노드수 : 1개\n",
    "        self.__W3 = np.random.rand(6,1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "        print(self.name + \" object is created\")\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        delta = 1e-7\n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z2 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = a3 = sigmoid(z2)\n",
    "        \n",
    "        #cross - entropy\n",
    "        return -np.sum(self.__tdata*np.log(y+delta)+(1-self.__tdata)*np.log((1-y)+delta))\n",
    "    \n",
    "    def loss_val(self):\n",
    "        delta = 1e-7\n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z2 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = a3 = sigmoid(z2)\n",
    "        \n",
    "        #cross - entropy\n",
    "        return -np.sum(self.__tdata*np.log(y+delta)+(1-self.__tdata)*np.log((1-y)+delta))\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x : self.feed_forward()\n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "\n",
    "        for step in range(10001):\n",
    "\n",
    "            # 은닉층이 여러개 이기 때문에 가중치와 바이어스도 여러개 초기화\n",
    "            self.__W2 -= self.__learning_rate*numerical_derivative(f,self.__W2)\n",
    "            self.__b2 -= self.__learning_rate*numerical_derivative(f,self.__b2)\n",
    "            self.__W3 -= self.__learning_rate*numerical_derivative(f,self.__W3)\n",
    "            self.__b3 -= self.__learning_rate*numerical_derivative(f,self.__b3)\n",
    "            \n",
    "            if(step % 400 == 0):\n",
    "                print(\"step = \", step )\n",
    "                print(\"loss_value = \", self.loss_val())\n",
    "                    \n",
    "    # 학습을 모두 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "    def predict(self, x_data):\n",
    "\n",
    "        z2=np.dot(x_data,self.__W2)+self.__b2\n",
    "        a2=sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2,self.__W3)+self.__b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "\n",
    "        if y>0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND GATE 검증 - 딥러닝 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND object is created\n",
      "Initial loss value =  11.72063812811218\n",
      "step =  0\n",
      "error_value =  11.382290453642819\n",
      "step =  400\n",
      "error_value =  2.214157850049424\n",
      "step =  800\n",
      "error_value =  2.062999279987834\n",
      "step =  1200\n",
      "error_value =  1.8482319764911073\n",
      "step =  1600\n",
      "error_value =  1.5552401042747799\n",
      "step =  2000\n",
      "error_value =  1.213283503213511\n",
      "step =  2400\n",
      "error_value =  0.8907881089631187\n",
      "step =  2800\n",
      "error_value =  0.6440247348054849\n",
      "step =  3200\n",
      "error_value =  0.4744899228369944\n",
      "step =  3600\n",
      "error_value =  0.3604872998410315\n",
      "step =  4000\n",
      "error_value =  0.28261810600467996\n",
      "step =  4400\n",
      "error_value =  0.22791469852654195\n",
      "step =  4800\n",
      "error_value =  0.18830101368044944\n",
      "step =  5200\n",
      "error_value =  0.15877851741368276\n",
      "step =  5600\n",
      "error_value =  0.13620035694685537\n",
      "step =  6000\n",
      "error_value =  0.11853507655608056\n",
      "step =  6400\n",
      "error_value =  0.1044353613326193\n",
      "step =  6800\n",
      "error_value =  0.09298377074517661\n",
      "step =  7200\n",
      "error_value =  0.08353997710477838\n",
      "step =  7600\n",
      "error_value =  0.07564682480548619\n",
      "step =  8000\n",
      "error_value =  0.06897113688842035\n",
      "step =  8400\n",
      "error_value =  0.063265515294389\n",
      "step =  8800\n",
      "error_value =  0.0583431234809738\n",
      "step =  9200\n",
      "error_value =  0.054060682196616985\n",
      "step =  9600\n",
      "error_value =  0.05030677538761387\n",
      "step =  10000\n",
      "error_value =  0.04699366026347658\n"
     ]
    }
   ],
   "source": [
    "# AND GATE 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,0,0,1])\n",
    "\n",
    "and_obj = LogicGate(\"AND\", xdata, tdata)\n",
    "\n",
    "and_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.00018686]), 0)\n",
      "(array([0.0119545]), 0)\n",
      "(array([0.97804638]), 1)\n",
      "(array([0.01250364]), 0)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0,0],[0,1],[1,1],[1,0]])\n",
    "\n",
    "for data in test_data:\n",
    "    print(and_obj.predict(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR GATE 검증 - 딥러닝 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR object is created\n",
      "Initial loss value =  5.696271135977234\n",
      "step =  0\n",
      "loss_value =  5.565936624381372\n",
      "step =  400\n",
      "loss_value =  2.7672290875993824\n",
      "step =  800\n",
      "loss_value =  2.761450680901325\n",
      "step =  1200\n",
      "loss_value =  2.7544318131820393\n",
      "step =  1600\n",
      "loss_value =  2.745376074362542\n",
      "step =  2000\n",
      "loss_value =  2.7332099558562573\n",
      "step =  2400\n",
      "loss_value =  2.716487234023885\n",
      "step =  2800\n",
      "loss_value =  2.6933098232983728\n",
      "step =  3200\n",
      "loss_value =  2.661315312731451\n",
      "step =  3600\n",
      "loss_value =  2.6178704120010563\n",
      "step =  4000\n",
      "loss_value =  2.560739521405524\n",
      "step =  4400\n",
      "loss_value =  2.489353155586027\n",
      "step =  4800\n",
      "loss_value =  2.405934957807067\n",
      "step =  5200\n",
      "loss_value =  2.31504189788566\n",
      "step =  5600\n",
      "loss_value =  2.2214156701263663\n",
      "step =  6000\n",
      "loss_value =  2.12794322081186\n",
      "step =  6400\n",
      "loss_value =  2.034989393731674\n",
      "step =  6800\n",
      "loss_value =  1.9407043922006018\n",
      "step =  7200\n",
      "loss_value =  1.8414790761196458\n",
      "step =  7600\n",
      "loss_value =  1.7325132458593555\n",
      "step =  8000\n",
      "loss_value =  1.6095547173087705\n",
      "step =  8400\n",
      "loss_value =  1.4724227479834837\n",
      "step =  8800\n",
      "loss_value =  1.3270322280751505\n",
      "step =  9200\n",
      "loss_value =  1.1822451927469744\n",
      "step =  9600\n",
      "loss_value =  1.0453449373847412\n",
      "step =  10000\n",
      "loss_value =  0.9204767778908549\n"
     ]
    }
   ],
   "source": [
    "# XOR GATE 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "tdata = np.array([0,1,1,0])\n",
    "\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.11477826]), 0)\n",
      "(array([0.77895381]), 1)\n",
      "(array([0.81603716]), 1)\n",
      "(array([0.29210625]), 0)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "\n",
    "for data in test_data:\n",
    "    print(xor_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
